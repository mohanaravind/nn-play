<!--
TODO: 
1. Excel style input editor
-->

<link rel="import" href="../bower_components/polymer/polymer-element.html">
<link rel="import" href="shared-styles.html">
<link rel="import" href="lib/imports.html">

<dom-module id="my-view1">
  <template>
    <style include="shared-styles">
       :host {
        display: block;

        padding: 10px;
      }

      .container {
        display: flex;
        justify-content: center;
      }

      .layer {
        display: flex;
        flex-direction: column;
        justify-content: center;
      }

      .neuron {
        border-radius: 18px;
      }

      .inp {
        background-color: #f4cccc;
      }

      .hidden {
        background-color: #c9d9f8;
      }

      .out {
        background-color: #d8e9d3;
      }
    </style>

    <div class="card">
      <h1>Hyperparameters</h1>
      <div>

        <div class="hyperparameters-row">
          <labe>Layers</label>
            <input id="layers" type="text" value="3x4x1" />
        </div>
        <div class="hyperparameters-row">
          <labe>Learning Rate</label>
            <input id="learningrate" type="number" min="0.0001" max="0.01" value="0.01" />
        </div>
        <div class="hyperparameters-row">
          <labe>Epochs</label>
            <input id="epochs" type="number" value="1" />
        </div>
        <div class="hyperparameters-row">
          <labe>Regularization</label>
            <input id="regularization" type="number" value="0.1" />
        </div>
        <div class="hyperparameters-row">
          <labe>Batchsize</label>
            <select id="activation">
              <option value="32">32</option>
              <option value="64">64</option>
              <option value="128">128</option>
              <option value="256">256</option>
              <option value="512">512</option>             
          </select>
        </div>
        <div class="hyperparameters-row">
          <labe>Activation</label>
          <select id="activation">
            <option value="sigmoid">Sigmoid Function</option>
            <option value="relu">ReLU Function</option>
          </select>
        </div>


        <button on-click="_update">Update</button>

        <button on-click="_prepData">Prepare Data</button>

        <button on-click="_train">Train</button>
      </div>
    </div>

    <div class="card container">
      <div class="card layer inp">
        <template is="dom-repeat" items="[[network.inputs]]">
          <div class="card neuron">

          </div>
        </template>
      </div>

      <template is="dom-repeat" items="[[network.hiddenLayers]]">
        <div class="card layer hidden">
          <template is="dom-repeat" items="[[item]]">
            <div class="card neuron">

            </div>
          </template>
        </div>
      </template>

      <div class="card layer out">
        <template is="dom-repeat" items="[[network.outputs]]">
          <div class="card neuron">

          </div>
        </template>
      </div>
    </div>
  </template>
  <script src="../bower_components/numjs/dist/numjs.min.js"></script>  
  <script>

    class MyView1 extends Polymer.Element {
      constructor() {
        super();
      }

      static get is() { return 'my-view1'; }

      ready() {
        super.ready();

        this._update();
      }

      static get properties() {
        return {
          neuralNetwork: {
            type: NeuralNetwork
          }
        };
      }

      //Update the network info with all hyperparameters and layers information
      _update() {
        const arch = this.$.layers.value.split('x').map(layer => Number(layer));

        const info = {
          architecture: arch.slice(),
          inputsCount: arch.shift(),
          outputsCount: arch.pop(),
          hiddenLayers: arch.map(count => new Array(count)),
          learningrate: parseFloat(this.$.learningrate.value),
          epochs: this.$.epochs.value,
          activation: this.$.activation.options[this.$.activation.selectedIndex].value
        };

        //TODO: Avoid this and use only one entity (Neural Network)
        //For the UI
        this.network = {
          inputs: Array(info.inputsCount),
          outputs: Array(info.outputsCount),
          hiddenLayers: info.hiddenLayers
        };

        //Instantiate the network
        //TODO: Make this dynamic based on the selected type of network
        this.neuralNetwork = new FullyConnected(info);
      }

      _prepData() {
        //TODO: Use dropdown to dynamically allow selection of sample data
        //TODO: Update the layers input & output count and do the _update based on sample data

        Log.info('Data preparation started...');
        
        //Get sample data
        const data = SampleData.binarySample1();
        // const data =SampleData.sinCos();
        
        //Add it to the network info
        this.neuralNetwork.setData(data);

        Log.success('Data preparation completed!');
      }

      /*
        x
        Before weight multiplication
        
        feedIn
        After weight multiplication but before activation
        
        feedOut
        After activation
      */
      _train() {
        Log.info('Training started...');

        //Get the network        
        const nn = this.neuralNetwork;

        //Get necessary info about the neural network
        const epochs = nn.info.epochs;
        const { inputs, labels } = nn.data;        
        
        for (let epoch = 0; epoch < epochs; epoch++) {
          if(!(epoch % 300)) {
            Log.info(`Epoch: ${epoch}`);
          }
          
          //TODO: Do this after vectorizing the inputs as batches
          //Loop through all the inputs          
          inputs.forEach( (input, idx) => {          
            //Do forward propagation
            const output = nn.forward(input);

            //Get the labels
            const y = nj.array(labels[idx]);
            // Compute the mean squared error (MSE)            
            // let error = y.subtract(output).pow(2).divide(batchSize);
            // const error = y.subtract(output).pow(2);
            //#####CONFUSED over here#####
            const error = output.subtract(y) 

            //Do backward propagation
            nn.backward(error);            

            if(!(epoch % 300)) {
              //Print the stats
              const exp = y.toString();
              const out = output.toString();
              const err = error.toString();
              console.log(`Expected: ${exp} | Output: ${out} | Error: ${err}`);              
            }
          });

          //Adjust the weights by learning from the mistakes
          nn.learn();
        }

        Log.success('Training completed!');
      }
    }

    window.customElements.define(MyView1.is, MyView1);
  </script>
</dom-module>