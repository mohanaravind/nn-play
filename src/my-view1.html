<!--
TODO: 
1. Excel style input editor
-->

<link rel="import" href="../bower_components/polymer/polymer-element.html">
<link rel="import" href="shared-styles.html">

<dom-module id="my-view1">
  <template>
    <style include="shared-styles">
       :host {
        display: block;

        padding: 10px;
      }

      .container {
        display: flex;
        justify-content: center;
      }

      .layer {
        display: flex;
        flex-direction: column;
        justify-content: center;
      }

      .neuron {
        border-radius: 18px;
      }

      .inp {
        background-color: #f4cccc;
      }

      .hidden {
        background-color: #c9d9f8;
      }

      .out {
        background-color: #d8e9d3;
      }
    </style>

    <div class="card">
      <h1>Hyperparameters</h1>
      <div>

        <div class="hyperparameters-row">
          <labe>Layers</label>
            <input id="layers" type="text" value="3x4x1" />
        </div>
        <div class="hyperparameters-row">
          <labe>Learning Rate</label>
            <input id="learningrate" type="number" value="0.01" />
        </div>
        <div class="hyperparameters-row">
          <labe>Epochs</label>
            <input id="epochs" type="number" value="1" />
        </div>
        <div class="hyperparameters-row">
          <labe>Regularization</label>
            <input id="regularization" type="number" value="0.1" />
        </div>
        <div class="hyperparameters-row">
          <labe>Batchsize</label>
            <input id="batchsize" type="number" value="120" />
        </div>
        <div class="hyperparameters-row">
          <labe>Activation</label>
            <select id="activation">
            <option value="sigmoid">Sigmoid Function</option>
          </select>
        </div>


        <button on-click="_update">Update</button>

        <button on-click="_prepData">Prepare Data</button>

        <button on-click="_train">Train</button>
      </div>
    </div>

    <div class="card container">
      <div class="card layer inp">
        <template is="dom-repeat" items="[[network.inputs]]">
          <div class="card neuron">

          </div>
        </template>
      </div>

      <template is="dom-repeat" items="[[network.hiddenLayers]]">
        <div class="card layer hidden">
          <template is="dom-repeat" items="[[item]]">
            <div class="card neuron">

            </div>
          </template>
        </div>
      </template>

      <div class="card layer out">
        <template is="dom-repeat" items="[[network.outputs]]">
          <div class="card neuron">

          </div>
        </template>
      </div>
    </div>
  </template>
  <script src="../bower_components/numjs/dist/numjs.min.js"></script>
  <script>
    //Activations
    class Activation {
      static sigmoid(x) {
        // 1/(1 + e^-x)        
        let res = x.exp();
        res = res.pow(-1);
        res = res.add(1);
        res = res.pow(-1);

        return res;
      }

      static sigmoid_prime(x) {
        // x = sigmoid(x); return x * (1-x)
        const xSquared = x.pow(2);          
        return x.subtract(xSquared);
      }
    }

    //Samples
    class SampleData {
      //TODO: https://archive.ics.uci.edu/ml/datasets.html
      static binarySample1() {
        const inputs = [
          [0, 0, 1],
          [1, 1, 1],
          [1, 0, 1],
          [0, 1, 1]
        ];

        const labels = [
          [0],
          [1],
          [1],
          [0]
        ];
        
        return {          
          inputs,
          labels
        };
      }

      static sinCos() {        
        //  y = sin(x) + cos(x)
        const inputs = [];
        const labels = [];
        for (let idx = 1; idx < 5; idx++) {	
          const x1 = Math.sin(idx);
          const x2 = Math.cos(idx);

          inputs.push([x1, x2]);
          labels.push(x1 + x2 > 0 ? [1, 0] : [0, 1]);
        }
        
        return {          
          inputs,
          labels
        };
      }
    }

    //Helper
    class Log {
      static success (message) {
        console.log(`%c ${message}! `, 'background:#8BC34A; color:black;border-radius:2px');
      }

      static info (message) {
        console.log(`%c ${message}! `, 'background:#CDDC39; color:black;border-radius:2px');
      }

    }

    class Network {

      constructor () {
        
      }

      forward() {
        weights.forEach((weight, idx) => {
          const feedIn = nj.dot(x, weight);
          const feedOut = Activation.sigmoid(feedIn);

          //Preserve
          layers.push({x, weight, feedIn, feedOut });

          //Set this as input for the next layer
          x = feedOut;              
        });
      }
    }

    class MyView1 extends Polymer.Element {
      constructor() {
        super();
      }

      static get is() { return 'my-view1'; }

      ready() {
        super.ready();

        this._update();
      }

      static get properties() {
        return {
          networkInfo: {
            type: Object
          }
        };
      }

      //Update the network info with all hyperparameters and layers information
      _update() {
        const layers = this.$.layers.value.split('x').map(layer => Number(layer));

        const networkInfo = {
          layers: layers.slice(),
          inputsCount: layers.shift(),
          outputsCount: layers.pop(),
          hiddenLayers: layers.map(count => new Array(count)),
          learningrate: parseFloat(this.$.learningrate.value),
          epochs: this.$.epochs.value,
          activation: this.$.activation.options[this.$.activation.selectedIndex].value
        };

        //For the UI
        this.network = {
          inputs: Array(networkInfo.inputsCount),
          outputs: Array(networkInfo.outputsCount),
          hiddenLayers: networkInfo.hiddenLayers
        };

        //Expose the network information
        this.networkInfo = networkInfo;
      }

      _prepData() {
        //TODO: Use dropdown to dynamically allow selection of sample data
        //TODO: Update the layers input & output count and do the _update based on sample data

        Log.info('Data preparation started...');
        

        const data = SampleData.binarySample1();
        // const data =SampleData.sinCos();
        
        //Add it to the network info
        this.networkInfo = {
          ...this.networkInfo,
          ...data
        };

        Log.success('Data preparation completed!');
      }



      

      /*
        x
        Before weight multiplication
        
        feedIn
        After weight multiplication but before activation
        
        feedOut
        After activation
      */
      _train() {
        Log.info('Training started...');

        //Get the network parameters
        const net = this.networkInfo;

        //Initialize the weights
        let weights = [];        
        let weights_delta = [];
        for (let idx = 0; idx + 1 < net.layers.length; idx++) {
          weights.push(nj.random([net.layers[idx], net.layers[idx + 1]]));
          weights_delta.push(nj.zeros(weights[idx].shape));
        }

        for (let epoch = 0; epoch < net.epochs; epoch++) {
          //Number of training samples
          const m = net.inputs.length;

          //Loop through all the inputs
          net.inputs.forEach( (x, idx) => {            
            ///////////////////////
            //FORWARD PROPAGATION//
            ///////////////////////

            const layers = [];
            x = nj.array(x);
            weights.forEach((weight, idx) => {
              const feedIn = nj.dot(x, weight);
              const feedOut = Activation.sigmoid(feedIn);

              //Preserve
              layers.push({x, weight, feedIn, feedOut });

              //Set this as input for the next layer
              x = feedOut;              
            });

            ////////////////////////
            //BACKWARD PROPAGATION//
            ////////////////////////
            
            //Get the labels
            let y = nj.array(net.labels[idx]);
            //Compute the error
            let error = y.subtract(layers[layers.length - 1].feedOut);

            //Go through the layers in reverse order
            for (let idx = layers.length - 1; idx > -1; idx--) {        
              const layer = layers[idx];

              //Calculate the gradient
              let gradient = Activation.sigmoid_prime(layer.feedOut).multiply(error);
              //Backprop the error
              error = nj.dot(layer.weight, gradient);

              //Reshape and compute the effect on the weight              
              let A = nj.array([layer.x.tolist()]);
              let B = nj.array([gradient.tolist()])
              let weight_gradient = A.T.dot(B);

              //Accumulate the weight gradient (Sum of gradients of all inputs)
              weights_delta[idx] = weights_delta[idx].add(weight_gradient);
            }
          });

          //Make the correction to the weights
          weights = weights.map((weight, idx) => {
            //Get the change that needs to be done to the weight
            const delta = weights_delta[idx].multiply(net.learningrate);
            //Clear the weight delta from the accumulator so to be ready for next epoch
            weights_delta[idx] = nj.zeros(weight.shape);

            return weight.add(delta);
          });

        }

        Log.success('Training completed!');
      }
    }

    window.customElements.define(MyView1.is, MyView1);
  </script>
</dom-module>